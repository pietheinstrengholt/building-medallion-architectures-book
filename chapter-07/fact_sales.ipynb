{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf765c0-f89d-436e-a322-df6b9ee42fe8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\"spark.sql.parquet.vorder.enabled\", \"true\"\n",
    "\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\"\n",
    "\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83e900-da0f-49b2-a99e-5da0d0e62464",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Load data to the dataframes\n",
    "orderdetail = spark.read.table(\"silver.adventureworks.hist_salesorderdetail\") \\\n",
    ".where(col(\"current\") == True)\n",
    "orderdetail = orderdetail.dropDuplicates([\"SalesOrderID\"])\n",
    "orderdetail = orderdetail[[\"SalesOrderID\", \"SalesOrderDetailID\", \\\n",
    "\"ProductID\", \"OrderQty\", \"UnitPrice\"]]\n",
    "orderdetail = orderdetail \\\n",
    ".withColumn(\"Revenue\",orderdetail[\"OrderQty\"] \\\n",
    "* orderdetail[\"UnitPrice\"] )\n",
    "\n",
    "orderheader = spark.read.table(\"silver.adventureworks.hist_salesorderheader\") \\\n",
    ".where(col(\"current\") == True)\n",
    "orderheader = orderheader.dropDuplicates([\"SalesOrderID\"])\n",
    "orderheader = orderheader[[\"SalesOrderID\", \"CustomerID\", \\\n",
    "\"BillToAddressID\", \"OrderDate\"]]\n",
    "orderheader = orderheader \\\n",
    ".withColumnRenamed(\"SalesOrderID\", \"SalesOrderID2\")\n",
    "\n",
    "# Perform the joins\n",
    "sales = orderdetail.join(orderheader, \\\n",
    "orderdetail['SalesOrderID'] == orderheader['SalesOrderID2'], \"left\")\n",
    "\n",
    "sales = sales.withColumn('SalesKey', concat(sales['SalesOrderID'], \\\n",
    "sales['SalesOrderDetailID']))\n",
    "\n",
    "# Select only the relevant columns\n",
    "sales = sales[[\"SalesKey\", \"ProductID\", \"CustomerID\", \\\n",
    "\"BillToAddressID\", \"Revenue\", \"OrderDate\", \"OrderQty\", \"UnitPrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a400fb-9c53-4eca-9d62-1cbf2f06f285",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load the dimension tables\n",
    "dimension_address = spark.read.table(\"adventureworks.dimension_address\") \\\n",
    ".where(col(\"current_flag\") == True)\n",
    "dimension_customer = spark.read.table(\"adventureworks.dimension_customer\") \\\n",
    ".where(col(\"current_flag\") == True)\n",
    "dimension_product = spark.read.table(\"adventureworks.dimension_product\") \\\n",
    ".where(col(\"current_flag\") == True)\n",
    "dimension_date = spark.read.table(\"adventureworks.dimension_date\")\n",
    "\n",
    "# Join the fact table with the dimension tables using the natural keys\n",
    "fact_sales = sales.join(dimension_address,(sales.BillToAddressID \\\n",
    "    == dimension_address.AddressID), \"left\") \\\n",
    "    .join(dimension_customer,(sales.CustomerID \\\n",
    "    == dimension_customer.CustomerID), \"left\") \\\n",
    "    .join(dimension_product,(sales.ProductID \\\n",
    "    == dimension_product.ProductID), \"left\") \\\n",
    "    .join(dimension_date,(sales.OrderDate \\\n",
    "    == dimension_date.OrderDate), \"left\") \\\n",
    "    .select(col(\"dimension_address.ID\").alias(\"AddressKey\"), \\\n",
    "    col(\"dimension_customer.ID\").alias(\"CustomerKey\"), \\\n",
    "    col(\"dimension_product.ID\").alias(\"ProductKey\"), \\\n",
    "    col(\"dimension_date.ID\").alias(\"DateKey\"), \\\n",
    "    col(\"SalesKey\"), col(\"Revenue\"), col(\"OrderQty\"), col(\"UnitPrice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6f768-75be-4f6a-a451-5fc68e7fa077",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "    \n",
    "deltaTable = DeltaTable.forPath(spark, \\\n",
    "'Tables/adventureworks/fact_sales')\n",
    "  \n",
    "deltaTable.alias('gold') \\\n",
    "  .merge(\n",
    "    fact_sales.alias('updates'),\n",
    "    'gold.SalesKey = updates.SalesKey \\\n",
    "    AND gold.AddressKey = updates.AddressKey \\\n",
    "    AND gold.CustomerKey = updates.CustomerKey \\\n",
    "    AND gold.ProductKey = updates.ProductKey \\\n",
    "    AND gold.DateKey = updates.DateKey' \\\n",
    "  ).whenMatchedUpdate(set =\n",
    "    {\n",
    "      \"current_flag\": lit(\"1\"),\n",
    "      \"current_date\": current_date(),\n",
    "      \"end_date\": \"\"\"to_date('9999-12-31', 'yyyy-MM-dd')\"\"\"\n",
    "    }\n",
    "  ).whenNotMatchedInsert(values =\n",
    "    {\n",
    "      \"SalesKey\": \"updates.SalesKey\",\n",
    "      \"AddressKey\": \"updates.AddressKey\",\n",
    "      \"CustomerKey\": \"updates.CustomerKey\",\n",
    "      \"ProductKey\": \"updates.ProductKey\",\n",
    "      \"DateKey\": \"updates.DateKey\",\n",
    "      \"Revenue\": \"updates.Revenue\",\n",
    "      \"OrderQty\": \"updates.OrderQty\",\n",
    "      \"UnitPrice\": \"updates.UnitPrice\",\n",
    "      \"current_flag\": lit(\"1\"),\n",
    "      \"current_date\": current_date(),\n",
    "      \"end_date\": \"\"\"to_date('9999-12-31', 'yyyy-MM-dd')\"\"\"\n",
    "    }\n",
    "  ).whenNotMatchedBySourceUpdate(set =\n",
    "    {\n",
    "      \"current_flag\": lit(\"0\"),\n",
    "      \"end_date\": current_date()\n",
    "    }\n",
    "  ).execute()"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "89b49d86-b090-4126-b03c-263e6f504321",
    "default_lakehouse_name": "Gold",
    "default_lakehouse_workspace_id": "30950d63-22f3-4d65-8813-310477df47b4",
    "known_lakehouses": [
     {
      "id": "89b49d86-b090-4126-b03c-263e6f504321"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    },
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
